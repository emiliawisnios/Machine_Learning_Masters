{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeRy_Ng0lfDT"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego \n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\" \n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>\n",
        "\n",
        "**Author: Tomasz Pawłowski**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML in big scale - LAB 1"
      ],
      "metadata": {
        "id": "0uEERM15Z3i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plan\n",
        "\n",
        "1. Setting up pyspark\n",
        "2. Map-Reduce word count example\n",
        "3. Map-Reduce exercises\n",
        "4. Homework\n",
        "\n"
      ],
      "metadata": {
        "id": "Ao9tweXeZr_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **edit the colab** first copy it to your drive with the top bars `File -> Save a copy on drive` option."
      ],
      "metadata": {
        "id": "w5XTROAjE7ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up PySpark\n",
        " "
      ],
      "metadata": {
        "id": "qdrOqKrbbWEi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxqy7fQ2Zn_u",
        "outputId": "01fe657c-d4f7-401f-bba7-c5b1e2c1dffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 62 kB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 79.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet \n",
        "!apt install openjdk-8-jdk-headless &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "hvP2cvhBb-gi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().set('spark.ui.port', '4050').setAppName(\"mlibs\").setMaster(\"local[2]\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)"
      ],
      "metadata": {
        "id": "IRX13sVIcU9Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: pyspark documentation is [here](https://spark.apache.org/docs/3.1.2/api/python/reference/index.html). For example: list of `SparkContext` methods is [here](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#spark-context-apis).\n"
      ],
      "metadata": {
        "id": "fC4mnbWTYtkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Loading data"
      ],
      "metadata": {
        "id": "qGTb1EnMFy9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Loading* data to clusters RAM. In spark such distributed datasets are called [RDD](https://spark.apache.org/docs/latest/rdd-programming-guide.html#resilient-distributed-datasets-rdds). They are divided into partitions which can be processed independently by different workers.\n",
        "\n",
        "`RDD` can be created from python collection, or by loading data from a file.\n"
      ],
      "metadata": {
        "id": "ckyobZb8ZtJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From python iterable"
      ],
      "metadata": {
        "id": "XUtLR5z2dUNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_partitions = 4\n",
        "\n",
        "array_of_numbers = [1, 2, 3, 4, 5]\n",
        "rdd_of_numbers = sc.parallelize(array_of_numbers, number_of_partitions)\n",
        "\n",
        "# `glom` shows how data is distributed in partitions\n",
        "rdd_of_numbers.glom().collect()"
      ],
      "metadata": {
        "id": "G_NdrZeQNO5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82df277-2566-45b3-989b-5081e127c78f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1], [2], [3], [4, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From google drive"
      ],
      "metadata": {
        "id": "qkQdwLSvdayo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data from google drive. Based on [tutorial](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=eFOvsAYk1tcH). Note that loading from google drive is useful but not required for this lab. You can also upload files to colab using the left menu bars `Files` menu, but such files are not persisted.\n",
        "\n",
        "Note that using google drive from other account that from which you open notebooks may not work."
      ],
      "metadata": {
        "id": "scY25PLEZrM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV7TE2B_Pk7t",
        "outputId": "ed216550-bde0-4e92-8424-203811591ebe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your google drive should now be mounted in the `/content/drive/My Drive/` local directory of this colab. \n",
        "\n",
        "The next code fragment assumes that you have there the following directory/file: `dir_on_my_drive/input.txt`. There is no file `input.txt`, you can create an empty one. This is just an example how to use p"
      ],
      "metadata": {
        "id": "K8X6wp8g3frp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# first upload input.txt to your gdrive!\n",
        "path = \"/content/drive/My Drive/dir_on_my_drive/input.txt\"\n",
        "if os.path.isfile(path):\n",
        "  lines_from_drive_file = sc.textFile(path)\n",
        "  print(lines_from_drive_file.collect())\n",
        "  # ..."
      ],
      "metadata": {
        "id": "Jb9DBoKnRuSF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "tMI04msQQbsD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From online resource "
      ],
      "metadata": {
        "id": "DsjREihyddzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading data to colab (machine executing the colab's) from an online source can be done using `wget` shell tool. Note the exclamation mark (!) before the command which indicates that this line should be executed by shell not python.\n",
        "\n",
        "Note that such downloaded files are not persisted. They are deleted after closing the colab session."
      ],
      "metadata": {
        "id": "dI7qa_-XFj5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://wolnelektury.pl/media/book/txt/balladyna.txt -O sample_data/balladyna.txt\n",
        "!wget -q https://wolnelektury.pl/media/book/txt/zemsta.txt -O sample_data/zemsta.txt"
      ],
      "metadata": {
        "id": "FTXB7EFbWVug"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading such files are visible in left menu bars `Files` section in `sample_data` directory.\n",
        "\n",
        "They can be accessed from python code using path: `sample_data/balladyna.txt`. "
      ],
      "metadata": {
        "id": "kFl3cdp3eZnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sample_data/balladyna.txt', 'r') as f:\n",
        "  for i, line in enumerate(f.readlines()):\n",
        "    print(f\"{i}: {line}\", end='')\n",
        "    if i > 15:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPyvvCqOgZcf",
        "outputId": "85e1b9d9-baa2-4cf8-d17f-7be99be57637"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Juliusz Słowacki\n",
            "1: \n",
            "2: Balladyna\n",
            "3: Tragedia w pięciu aktach\n",
            "4: \n",
            "5: ISBN 978-83-288-2852-0\n",
            "6: \n",
            "7: \n",
            "8: \n",
            "9: \n",
            "10: KOCHANY POETO RUIN!\n",
            "11: \n",
            "12: Pozwól, że pisząc do ciebie zacznę od apologu, który mi opowiedziano nad Salaminy zatoką.\n",
            "13: \n",
            "14: Stary i ślepy harfiarz z wyspy Scio przyszedł nad brzegi Morza Egejskiego, a usłyszawszy z wielkim hukiem łamiące się fale; myślał, że szum ów pochodził od zgiełku ludzi, którzy się zbiegli pieśni rycerskich posłuchać. — Oparł się więc na harfie i śpiewał pustemu morza brzegowi: a kiedy skończył, zadziwił się, że żadnego ludzkiego głosu, żadnego westchnienia, żadnego pieśń nie zyskała oklasku. Rzucił więc harfę precz daleko od siebie, a te fale, które śpiewak mniemał tłumem ludzkim, odniosły złote pieśni narzędzie i położyły mu je przy stopach. I odszedł od harfy swojej smutny Greczyn nie wiedząc, że najpiękniejszy rapsod nie w sercach ludzi, ale w głębi fal Egejskiego Morza utonął.\n",
            "15: \n",
            "16: Kochany Irydionie! ta powiastka o falach i harfiarzu zastąpi wszelką do Balladyny przemowę. Wychodzi na świat Balladyna z ariostycznym uśmiechem na twarzy, obdarzona wnętrzną siłą urągania się z tłumu ludzkiego, z porządku i z ładu, jakim się wszystko dzieje na świecie, z nieprzewidzianych owoców, które wydają drzewa ręką ludzi szczepione. Niech naprawiacz wszelkiego bezprawia Kirkor pada ofiarą swoich czystych zamiarów; niech Grabieć miłuje kuchnią Kirkora; niechaj powietrzna Goplana kocha się w rumianym chłopie, a sentymentalny Filon szuka umyślnie męczarni miłosnych i umarłej kochanki; niechaj tysiące anachronizmów przerazi śpiących w grobie historyków i kronikarzy: a jeżeli to wszystko ma wnętrzną siłę żywota, jeżeli stworzyło się w głowie poety podług praw boskich, jeżeli natchnienie nie było gorączką, ale skutkiem tej dziwnej władzy, która szepce do ucha nigdy wprzód nie słyszane wyrazy, a oczom pokazuje nigdy, we śnie nawet, nie widziane istoty; jeżeli instynkt poetyczny był lepszym od rozsądku, który nieraz tę lub ową rzecz potępił: to Balladyna wbrew rozwadze i historii zostanie królową polską — a piorun, który spadł na jej chwilowe panowanie, błyśnie i roztworzy mgłę dziejów przeszłości.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Saving data"
      ],
      "metadata": {
        "id": "ueSDCFgXgObp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are multiple save methods in [RDD API](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#rdd-apis)\n",
        "\n",
        "Here are some examples. After executing following two code examples check how the data is formatted."
      ],
      "metadata": {
        "id": "qGE-2xzXq4Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving as text file\n",
        "\n",
        "sc.parallelize([('a', 1), ('b', 2), ('c', 0), ('d', 1), ('e', 0)], 2).saveAsTextFile('save_example1')"
      ],
      "metadata": {
        "id": "349UWuCfro3h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving as pickle\n",
        "\n",
        "sc.parallelize([('x', 1), ('y', 2), ('z', 0), ('w', 1), ('ź', 4)], 2).saveAsPickleFile('save_example2')"
      ],
      "metadata": {
        "id": "UFxymwAVrpYm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that partitions are saved separately in their own directoires.\n",
        "\n",
        "Loading of pickled files is straightforward. For text files it can be loaded with [textFile](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.SparkContext.textFile.html#pyspark.SparkContext.textFile) but requires manual parsing. `glom` method used below visualizes how data is split between partitions."
      ],
      "metadata": {
        "id": "YChu20IpspmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.pickleFile('save_example2').glom().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucVBwxDvspON",
        "outputId": "05339073-25f1-4d1a-eaf8-03bc5912f375"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('z', 0), ('w', 1), ('ź', 4)], [('x', 1), ('y', 2)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map-Reduce sample interface"
      ],
      "metadata": {
        "id": "RtjIWtBidwxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You don't need to understand it, yet. Just execute this cell. The `map_reduce` method will be used in the following examples and exercises."
      ],
      "metadata": {
        "id": "wjzWTWa8LJET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import operator\n",
        "from pyspark import RDD\n",
        "from typing import Callable, Iterable, List, Tuple, TypeVar\n",
        "\n",
        "T = TypeVar('T')\n",
        "U = TypeVar('U')\n",
        "V = TypeVar('V')\n",
        "S = TypeVar('S')\n",
        "\n",
        "def map_reduce(\n",
        "    input: RDD[T], \n",
        "    map_function: Callable[[T], Iterable[Tuple[U, V]]], \n",
        "    reduce_function: Callable[[U, Iterable[V]], Iterable[S]],\n",
        "    combiner_function: Callable[[U, Iterable[V]], V] = None\n",
        "    ) -> RDD[S]:\n",
        "\n",
        "  mapped_rdd = input.flatMap(map_function, preservesPartitioning=True)\n",
        "\n",
        "  if combiner_function is not None:\n",
        "    def apply_combiner(partition: Iterable[Tuple[U, V]]) -> Iterable[Tuple[U, V]]:\n",
        "      it = itertools.groupby(partition, operator.itemgetter(0))\n",
        "      for key, values in it:\n",
        "        yield key, combiner_function(key, (v for _, v in values))\n",
        "\n",
        "    mapped_rdd = mapped_rdd.mapPartitions(apply_combiner, preservesPartitioning=True)\n",
        "\n",
        "  return mapped_rdd\\\n",
        "      .groupByKey()\\\n",
        "      .flatMap(lambda k_v: reduce_function(k_v[0], k_v[1]), preservesPartitioning=True)\n"
      ],
      "metadata": {
        "id": "XpIFGtSEE3rb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Word count"
      ],
      "metadata": {
        "id": "VjvTXPpQNH2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_from_file = sc.textFile('sample_data/balladyna.txt')\n",
        "\n",
        "lines_from_file.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS8BomsYXKJL",
        "outputId": "604d7082-2105-4845-c372-d54efebdc41f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Juliusz Słowacki',\n",
              " '',\n",
              " 'Balladyna',\n",
              " 'Tragedia w pięciu aktach',\n",
              " '',\n",
              " 'ISBN 978-83-288-2852-0',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'KOCHANY POETO RUIN!',\n",
              " '',\n",
              " 'Pozwól, że pisząc do ciebie zacznę od apologu, który mi opowiedziano nad Salaminy zatoką.',\n",
              " '',\n",
              " 'Stary i ślepy harfiarz z wyspy Scio przyszedł nad brzegi Morza Egejskiego, a usłyszawszy z wielkim hukiem łamiące się fale; myślał, że szum ów pochodził od zgiełku ludzi, którzy się zbiegli pieśni rycerskich posłuchać. — Oparł się więc na harfie i śpiewał pustemu morza brzegowi: a kiedy skończył, zadziwił się, że żadnego ludzkiego głosu, żadnego westchnienia, żadnego pieśń nie zyskała oklasku. Rzucił więc harfę precz daleko od siebie, a te fale, które śpiewak mniemał tłumem ludzkim, odniosły złote pieśni narzędzie i położyły mu je przy stopach. I odszedł od harfy swojej smutny Greczyn nie wiedząc, że najpiękniejszy rapsod nie w sercach ludzi, ale w głębi fal Egejskiego Morza utonął.',\n",
              " '',\n",
              " 'Kochany Irydionie! ta powiastka o falach i harfiarzu zastąpi wszelką do Balladyny przemowę. Wychodzi na świat Balladyna z ariostycznym uśmiechem na twarzy, obdarzona wnętrzną siłą urągania się z tłumu ludzkiego, z porządku i z ładu, jakim się wszystko dzieje na świecie, z nieprzewidzianych owoców, które wydają drzewa ręką ludzi szczepione. Niech naprawiacz wszelkiego bezprawia Kirkor pada ofiarą swoich czystych zamiarów; niech Grabieć miłuje kuchnią Kirkora; niechaj powietrzna Goplana kocha się w rumianym chłopie, a sentymentalny Filon szuka umyślnie męczarni miłosnych i umarłej kochanki; niechaj tysiące anachronizmów przerazi śpiących w grobie historyków i kronikarzy: a jeżeli to wszystko ma wnętrzną siłę żywota, jeżeli stworzyło się w głowie poety podług praw boskich, jeżeli natchnienie nie było gorączką, ale skutkiem tej dziwnej władzy, która szepce do ucha nigdy wprzód nie słyszane wyrazy, a oczom pokazuje nigdy, we śnie nawet, nie widziane istoty; jeżeli instynkt poetyczny był lepszym od rozsądku, który nieraz tę lub ową rzecz potępił: to Balladyna wbrew rozwadze i historii zostanie królową polską — a piorun, który spadł na jej chwilowe panowanie, błyśnie i roztworzy mgłę dziejów przeszłości.',\n",
              " '',\n",
              " 'Uśmiechnij się teraz, Irydionie, bo oto naśladując francuskich poetów: powiem ci, że Balladyna jest tylko epizodem wielkiego poematu w rodzaju Ariosta, który ma się uwiązać z sześciu tragedii, czyli kronik dramatycznych. Cienił już różne ludzi niebyłych wyszły ze mgły przedstworzenia i otaczają mnie ciżbą gwarzącą: potrzeba tylko, aby się zebrały w oddzielne tłumy, ażeby czyny ich ułożyły się w postacie piramidalne wypadków, a jedną po drugiej garstkę na świat wypychać będę; i sprawdzą się może sny mego dzieciństwa. Bo ileż to razy patrząc na stary zamek, koronujący ruinami górę mego rodzinnego miasteczka, marzyłem, że kiedyś w ten wieniec wyszczerbionych murów nasypię widm, duchów, rycerzy; że odbuduję upadłe sale i oświecę je przez okna ogniem piorunowych nocy, a sklepieniom każę powtarzać dawne Sofoklesowskie „niestety!” A za to imię moje słyszane będzie w szumie płynącego pod górą potoku, a jakaś niby tęcza z myśli moich unosić się będzie nad ruinami zamku. — O! nie mów mi, że z dzwonków polnych większa ozdoba ruinom niż z tego wieńca myśli, w który je ubierze poeta: — bo choć róże rosnące na ruinach pałacu Nerona rozwidniały nam pięknie te gruzy: to jednak jaśniej mi je oświecił ów duch Irydiona, któregoś ty pod krzyżem w Kolosseum położył i nakrył złotymi skrzydłami anioła.',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "\n",
        "example_words = lines_from_file.flatMap(lambda line: filter(None, re.split(r'\\s+', line.lower())))\n",
        "\n",
        "example_words.take(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73dh_irCXScy",
        "outputId": "4735a4b7-e8c7-4415-e80e-dc01e395db4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['juliusz',\n",
              " 'słowacki',\n",
              " 'balladyna',\n",
              " 'tragedia',\n",
              " 'w',\n",
              " 'pięciu',\n",
              " 'aktach',\n",
              " 'isbn',\n",
              " '978-83-288-2852-0',\n",
              " 'kochany',\n",
              " 'poeto',\n",
              " 'ruin!',\n",
              " 'pozwól,',\n",
              " 'że',\n",
              " 'pisząc',\n",
              " 'do',\n",
              " 'ciebie',\n",
              " 'zacznę',\n",
              " 'od',\n",
              " 'apologu,',\n",
              " 'który',\n",
              " 'mi',\n",
              " 'opowiedziano',\n",
              " 'nad',\n",
              " 'salaminy',\n",
              " 'zatoką.',\n",
              " 'stary',\n",
              " 'i',\n",
              " 'ślepy',\n",
              " 'harfiarz']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import RDD\n",
        "from typing import Tuple \n",
        "\n",
        "def word_count(words_rdd: RDD[str]) -> RDD[Tuple[str, int]]:\n",
        "  return map_reduce(\n",
        "      words_rdd, \n",
        "      lambda word: [(word, 1)], \n",
        "      lambda k, vs: [(k, sum(vs))]\n",
        "  )\n",
        "\n",
        "word_count(example_words).take(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1a4WzjZQR2n",
        "outputId": "99ca7863-589a-4157-c6ac-32fa8d294274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('juliusz', 3),\n",
              " ('balladyna', 263),\n",
              " ('kochany', 2),\n",
              " ('ruin!', 1),\n",
              " ('pozwól,', 2),\n",
              " ('do', 229),\n",
              " ('zacznę', 1),\n",
              " ('apologu,', 1),\n",
              " ('mi', 89),\n",
              " ('salaminy', 1),\n",
              " ('i', 518),\n",
              " ('ślepy', 1),\n",
              " ('harfiarz', 1),\n",
              " ('scio', 1),\n",
              " ('przyszedł', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count_with_combiner(words_rdd: RDD[str]) -> RDD[Tuple[str, int]]:\n",
        "  return map_reduce(\n",
        "      words_rdd,\n",
        "      lambda word: [(word, 1)], \n",
        "      lambda k, vs: [(k, sum(vs))],\n",
        "      lambda _, vs: sum(vs)\n",
        "  )\n",
        "\n",
        "word_count_with_combiner(example_words).take(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Y4901oXShP",
        "outputId": "425fe24b-7d24-4d97-bf1e-5650c418ccd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('juliusz', 3),\n",
              " ('balladyna', 263),\n",
              " ('kochany', 2),\n",
              " ('ruin!', 1),\n",
              " ('pozwól,', 2),\n",
              " ('do', 229),\n",
              " ('zacznę', 1),\n",
              " ('apologu,', 1),\n",
              " ('mi', 89),\n",
              " ('salaminy', 1),\n",
              " ('i', 518),\n",
              " ('ślepy', 1),\n",
              " ('harfiarz', 1),\n",
              " ('scio', 1),\n",
              " ('przyszedł', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Average"
      ],
      "metadata": {
        "id": "gYx8dsk2gJY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate average for given `RDD` of numbers. Use `map_reduce` utility method. Try to add a combiner function."
      ],
      "metadata": {
        "id": "iusCF9B6gFsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "def average(numbers_rdd: RDD[Union[int, float]]) -> float:\n",
        "    if numbers_rdd.isEmpty():\n",
        "      return float('NaN')\n",
        "\n",
        "    return map_reduce(\n",
        "        numbers_rdd,\n",
        "        lambda number: [(None, (number, 1))],\n",
        "        lambda k, vs: [(lambda values, counts: sum(values) / sum(counts))(*zip(*vs))]\n",
        "    ).collect()[0]"
      ],
      "metadata": {
        "id": "u1Sak9McuaYJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "    average(sc.parallelize([1,2,3,4,5,6])), # should be 3.5\n",
        "    average(sc.parallelize([42, 12])),      # should be 27 or 27.0\n",
        "    average(sc.parallelize([]))             # NaN or raise a meaningful exception \n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuALAexNiZiE",
        "outputId": "02c0e876-9c88-481a-e146-39335b48842c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.5, 27.0, nan]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "def average_solution_without_combiner(numbers_rdd: RDD[Union[int, float]]) -> float:\n",
        "  if numbers_rdd.isEmpty():\n",
        "    return float('NaN')\n",
        "\n",
        "  return map_reduce(\n",
        "      numbers_rdd,\n",
        "      lambda n: [(None, (n, 1))],\n",
        "      lambda k, vs: [(lambda values, counts: sum(values) / sum(counts))(*zip(*vs))]\n",
        "      ).collect()[0]\n",
        "  \n",
        "def average_solution_with_combiner(numbers_rdd: RDD[Union[int, float]]) -> float:\n",
        "  if numbers_rdd.isEmpty():\n",
        "    return float('NaN')\n",
        "\n",
        "  return map_reduce(\n",
        "      numbers_rdd,\n",
        "      lambda n: [(None, (n, 1))],\n",
        "      lambda k, vs: [(lambda values, counts: sum(values) / sum(counts))(*zip(*vs))],\n",
        "      lambda _, vs: (lambda values, counts: (sum(values), sum(counts)))(*zip(*vs))\n",
        "      ).collect()[0]"
      ],
      "metadata": {
        "id": "xFkFGAy1ba0k",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Jaccard similarity coefficient"
      ],
      "metadata": {
        "id": "yxZLm_9yf8Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute [Jaccard similarity coefficient](https://en.wikipedia.org/wiki/Jaccard_index) of two sets given by two RDD-s. Note: [union](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.SparkContext.union.html#pyspark.SparkContext.union) function may be needed. Use either `map_reduce` utility function or `map`, `flatMap`, `groupByKey` or other methods from [RDD](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#rdd-apis) directly.\n",
        "\n",
        "You can assume that both given `RDD`-s do not contain any duplicates."
      ],
      "metadata": {
        "id": "wVtmXbH7gBr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import RDD\n",
        "from typing import TypeVar\n",
        "\n",
        "T = TypeVar('T')\n",
        "\n",
        "def jaccard_similarity(a: RDD[T], b: RDD[T]) -> float:\n",
        "  if a.isEmpty() and b.isEmpty():\n",
        "    return float('NaN')\n",
        "    \n",
        "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
        "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
        "\n",
        "  elements_in_common, elements_in_sum = union.groupByKey().mapValues(len).aggregate(\n",
        "      (0, 0),\n",
        "      lambda x, y: ((x[0] + 1) if y[1] == 2 else x[0], x[1] + 1),\n",
        "      lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
        "  )\n",
        "\n",
        "  return elements_in_common / elements_in_sum"
      ],
      "metadata": {
        "id": "4YqkDoWAgcrF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "    jaccard_similarity(sc.parallelize([1,2,3]), sc.parallelize([2,3,4])), # 0.5\n",
        "    jaccard_similarity(sc.parallelize([1,2,3]), sc.parallelize([4,5])), # 0.0\n",
        "    jaccard_similarity(sc.parallelize(['a', 'b', 'c', 'd']), sc.parallelize(['c', 'b'])), # 0.5\n",
        "    jaccard_similarity(sc.parallelize([]), sc.parallelize([])) # NaN or raise a meaningful exception\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHPlSeV4hi8-",
        "outputId": "bcbc2f4f-a155-4be6-aa4f-3bc9ec29a492"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5, 0.0, 0.5, nan]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "def jaccard_similarity_solution(a: RDD[T], b: RDD[T]) -> float:\n",
        "  if a.isEmpty() and b.isEmpty():\n",
        "    return float('NaN')\n",
        "\n",
        "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
        "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
        "\n",
        "  elements_in_common, elements_in_sum = union.groupByKey().mapValues(len).aggregate(\n",
        "      (0, 0),\n",
        "      lambda x, y: ((x[0] + 1) if y[1] == 2 else x[0], x[1] + 1),\n",
        "      lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
        "  )\n",
        "\n",
        "  return elements_in_common / elements_in_sum"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U3xJIjLbvSzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Fetching online data\n",
        "\n",
        "Distribute fetching definitions of words from an online resource [Słownik języka polskiego](https://sjp.pl).\n",
        "\n",
        "Cell below downloads a database of words tagged as acceptable in word games."
      ],
      "metadata": {
        "id": "5_tNZYbN8Y1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://sjp.pl/sl/growy/sjp-20220807.zip -O sample_data/sjp-20220807.zip\n",
        "!rm -f sample_data/slowa.txt\n",
        "!unzip sample_data/sjp-20220807.zip slowa.txt -d sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7koSvgJL-Rs3",
        "outputId": "8b3891e6-cd59-4897-ea2a-9d8da9725b3e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sample_data/sjp-20220807.zip\n",
            "  inflating: sample_data/slowa.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prints example values\n",
        "\n",
        "words_rdd = sc.textFile('sample_data/slowa.txt')\n",
        "print(words_rdd.take(15))\n",
        "\n",
        "words_sample_rdd = words_rdd.sample(False, 20.0/words_rdd.count())\n",
        "print(words_sample_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oed74atC_hyl",
        "outputId": "2c1b563e-f310-4d92-d345-afdcced5a939"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aa', 'aaa', 'aalborscy', 'aalborska', 'aalborską', 'aalborski', 'aalborskich', 'aalborskie', 'aalborskiego', 'aalborskiej', 'aalborskiemu', 'aalborskim', 'aalborskimi', 'aalborsko', 'aalborsku']\n",
            "['fasetuje', 'goszczanowskie', 'kierowalności', 'nassała', 'niedwuliterowi', 'niefrontalny', 'nieopóźnieni', 'nierozświecana', 'niezwinnymi', 'ostwiami', 'podjadaniami', 'pozycjonowało', 'witano', 'wkruszmyż', 'zalepiłbym', 'znakarza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next cell shows how to download definitions of the word from the same source by parsing a html webpage."
      ],
      "metadata": {
        "id": "YaPL_0t4v6yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import RDD\n",
        "import re\n",
        "import ssl\n",
        "import urllib.parse\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "def fetch_definition(word: str) -> Iterable[str]:\n",
        "  definition_re = re.compile(r\"<p style=\\\"margin: \\.5em 0; font: medium[^\\\"]*\\\">([^<]+(?:<br />[^<]+)*)</p>\")\n",
        "  url = f\"https://sjp.pl/{urllib.parse.quote(word)}\"\n",
        "  response = urllib.request.urlopen(url, context=ssl._create_unverified_context())\n",
        "  html = response.read().decode(response.headers.get_content_charset())\n",
        "  return (d.group(1).replace('<br />', \"\\n\") for d in definition_re.finditer(html))\n",
        "  \n",
        "print(list(fetch_definition(\"test\")))\n",
        "print(list(fetch_definition(\"a kuku\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgRpva3QA04-",
        "outputId": "b3c1ca22-4979-46b4-ff58-e8153f3d9b01"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1. rodzaj pisemnego sprawdzianu, egzamin; zestaw odpowiednio przygotowanych pytań;\\n2. badanie, próba;\\n3. kontrolny obraz w odbiorniku telewizyjnym', 'partia wokalna w oratoriach, pełniąca funkcję narratora objaśniającego tło akcji i zaistniałą sytuację dramatyczną']\n",
            "['wyrażenie mające na celu zasygnalizowanie swojej obecności osobie niespodziewającej się tego']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using our `map_reduce` method and the function above a method that distributes downloading of the definitions of words can be created. Implement it as an exercise."
      ],
      "metadata": {
        "id": "I3_ymcgnwd5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_definitions(rdd: RDD[str]) -> RDD[Tuple[str, str]]:\n",
        "  return map_reduce(\n",
        "      rdd.repartition(12),\n",
        "      lambda word: [(word, None)], \n",
        "      lambda word, _: [(word, definition) for definition in fetch_definition(word)]\n",
        "  )"
      ],
      "metadata": {
        "id": "TC1LoIqbvhdr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "def fetch_definitions_solution(rdd: RDD[str]) -> RDD[Tuple[str, str]]:\n",
        "  return map_reduce(\n",
        "      rdd.repartition(12),\n",
        "      lambda word: [(word, None)], \n",
        "      lambda word, _: [(word, definition) for definition in fetch_definition(word)]\n",
        "  )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kO_R6uRlw8cL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_definitions = fetch_definitions(words_sample_rdd)\n",
        "\n",
        "for word, definition in word_definitions.collect():\n",
        "  print(word)\n",
        "  print(\" \", definition.replace(\"\\n\", \"\\n  \"))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMsArg8H2nV",
        "outputId": "7cee9c39-422a-48bc-b9b5-2c897b3f7033"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fasetuje\n",
            "  szlifować drogie kamienie lub metale w taki sposób, aby utworzyły się fasety\n",
            "\n",
            "niedwuliterowi\n",
            "  złożony z dwóch liter; biliterowy\n",
            "\n",
            "niefrontalny\n",
            "  1. znajdujący się na przedzie, ustawiony przodem;\n",
            "  2. skierowany ku przodowi kogoś lub czegoś;\n",
            "  3. atak frontalny - zmasowany atak na czoło frontu przeciwnika\n",
            "\n",
            "ostwiami\n",
            "  słup z żerdkami, na których układa się i suszy siano; ostrew, ostrewka, ostwica, suszak\n",
            "\n",
            "pozycjonowało\n",
            "  1. w informatyce: poprawiać pozycję strony internetowej w wynikach wyszukiwania;\n",
            "  2. w informatyce: rozmieszczać elementy graficzne na stronie internetowej;\n",
            "  3. określać miejsce, w którym znajduje się jakiś obiekt;\n",
            "  4. ustawiać w określonej pozycji;\n",
            "  5. ustalać pozycję firmy lub towaru na rynku w stosunku do konkurencji\n",
            "\n",
            "niezwinnymi\n",
            "  skoczny, zręczny, zwrotny;\n",
            "  1. taki, który porusza się szybko i sprawnie;\n",
            "  2. o ruchach: szybki i zgrabny, np. zwinne ręce\n",
            "\n",
            "znakarza\n",
            "  osoba zajmująca się wytyczaniem szlaków turystycznych\n",
            "\n",
            "wkruszmyż\n",
            "  krusząc coś, wsypać, dodać do czegoś; wdrobić\n",
            "\n",
            "goszczanowskie\n",
            "  przymiotnik od: Goszczanów\n",
            "\n",
            "nassała\n",
            "  1. wessać do czegoś płyn;\n",
            "  2. nassać się - ssać długo, do syta; zmęczyć się ssaniem\n",
            "\n",
            "witano\n",
            "  reagować w określony sposób przy spotkaniu kogoś, na widok czegoś\n",
            "\n",
            "zalepiłbym\n",
            "  zakryć jakąś powierzchnię, przyklejając coś do niej\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional exercise:\n",
        " \n",
        "Print words from `words_sample_rdd` for which no definition was found."
      ],
      "metadata": {
        "id": "j5kU5xyxIZH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def words_without_any_definition(words: RDD[str], word_definitions: RDD[Tuple[str, str]]) -> RDD[str]:\n",
        "  return words.map(lambda word: (word, 'S')).union(\n",
        "      word_definitions.map(lambda word_definition: (word_definition[0], 'D'))\n",
        "  ).groupByKey().flatMap(lambda word_tags: [word_tags[0]] if 'S' in word_tags[1] and 'D' not in word_tags[1] else [])"
      ],
      "metadata": {
        "id": "AF-2CV40Iil8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "def words_without_any_definition_solution(words: RDD[str], word_definitions: RDD[Tuple[str, str]]) -> RDD[str]:\n",
        "  return words.map(lambda word: (word, 'S')).union(\n",
        "      word_definitions.map(lambda word_definition: (word_definition[0], 'D'))\n",
        "  ).groupByKey().flatMap(lambda word_tags: [word_tags[0]] if 'S' in word_tags[1] and 'D' not in word_tags[1] else [])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0TQ6kvNnyIOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"words without any definition: {words_without_any_definition(words_sample_rdd, word_definitions).collect()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NHTv7Y8z0WN",
        "outputId": "0fe3378c-54aa-4900-a7ad-34a437632ac5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words without any definition: ['podjadaniami', 'nieopóźnieni', 'kierowalności', 'nierozświecana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 1: Set union, intersection and difference\n",
        "\n",
        "Given two sets in `RDD` format calculate their union, intersection and difference.\n",
        "\n",
        "Note: you can assume that there are no duplicates in given `RDD`-s. It is part of the exercise to make sure there will be no duplicates in the results."
      ],
      "metadata": {
        "id": "8jptMQSHLK4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import RDD\n",
        "from typing import TypeVar\n",
        "\n",
        "\n",
        "T = TypeVar('T')\n",
        "\n",
        "# calculates: a ∪ b\n",
        "def union(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
        "\n",
        "  sets_union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
        "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
        "\n",
        "  return sets_union.groupByKey().mapValues(len).map(lambda x: x[0])\n",
        "  \n",
        "\n",
        "# calculates: a ∩ b\n",
        "def intersection(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
        "\n",
        "  sets_intersection = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
        "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
        "\n",
        "  return sets_intersection.groupByKey().mapValues(len).filter(lambda x: x[1] == 2).map(lambda x: x[0])\n",
        "\n",
        "\n",
        "# calculates: a - b\n",
        "def difference(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
        "  sets_difference = a.map(lambda x: (x, 1), preservesPartitioning=True)\\\n",
        "      .union(b.map(lambda x: (x, -1), preservesPartitioning=True))\n",
        "\n",
        "  return sets_difference.groupByKey().mapValues(sum).filter(lambda x: x[1] > 0).map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "RvLdtTpMLIi2"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write more tests to make sure your solution works great\n",
        "\n",
        "a = sc.parallelize([1, 2, 3, 4])\n",
        "b = sc.parallelize([3, 4, 5])\n",
        "\n",
        "[\n",
        "    union(a, b).collect(),\n",
        "    intersection(a, b).collect(),\n",
        "    difference(a, b).collect(),\n",
        "    union(a, sc.emptyRDD()).collect(),\n",
        "    union(sc.emptyRDD(), a).collect(),\n",
        "    union(sc.emptyRDD(), sc.emptyRDD()).collect(),\n",
        "    intersection(a, sc.emptyRDD()).collect(),\n",
        "    intersection(sc.emptyRDD(), a).collect(),\n",
        "    intersection(sc.emptyRDD(), sc.emptyRDD()).collect(),\n",
        "    difference(a, sc.emptyRDD()).collect(),\n",
        "    difference(sc.emptyRDD(), a).collect(),\n",
        "    difference(sc.emptyRDD(), sc.emptyRDD()).collect()\n",
        "]"
      ],
      "metadata": {
        "id": "BCSce9caNGaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225bb6c3-2fe8-473f-e0b3-850bbad45ec2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 1, 5, 2, 3],\n",
              " [4, 3],\n",
              " [1, 2],\n",
              " [2, 4, 1, 3],\n",
              " [2, 4, 1, 3],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [2, 4, 1, 3],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 2: Join\n",
        "\n",
        "Write a function calculating natural join of two relations."
      ],
      "metadata": {
        "id": "d0vFtIIvOFUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import RDD\n",
        "from typing import Tuple, TypeVar\n",
        "import itertools\n",
        "\n",
        "T = TypeVar('T')\n",
        "U = TypeVar('U')\n",
        "V = TypeVar('V')\n",
        "\n",
        "\n",
        "# calculates all triples (x, y, z) such that (x,y)∈r and (y,z)∈s\n",
        "def join(r: RDD[Tuple[T, U]], s: RDD[Tuple[U, V]]) -> RDD[Tuple[T, U, V]]:\n",
        "\n",
        "    def dispatch(y, vals):\n",
        "      final_results = []\n",
        "      rbuf, sbuf = [], []\n",
        "      for val, label in vals:\n",
        "        if label == 'R':\n",
        "          rbuf.append(val)\n",
        "        elif label == 'S':\n",
        "          sbuf.append(val)\n",
        "      \n",
        "      pairs = itertools.product(rbuf, sbuf)\n",
        "      for (x, z) in pairs:\n",
        "        final_results.append((x, y, z))\n",
        "\n",
        "      return final_results\n",
        "\n",
        "    r_mapped = r.map(lambda v: (v[1], (v[0], 'R')))\n",
        "    s_mapped = s.map(lambda v: (v[0], (v[1], 'S')))\n",
        "    return r_mapped.union(s_mapped).groupByKey().map(lambda x: dispatch(x[0], x[1])).filter(lambda x: len(x)>0).flatMap(lambda x: x)\n"
      ],
      "metadata": {
        "id": "Z4TVOGIGOVBL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write more tests to make sure your solution works great\n",
        "\n",
        "a = sc.parallelize([(1, 'a'), (0, 'b'), (1, 'b')])\n",
        "b = sc.parallelize([('a', 12), ('a', 22), ('b', 12), ('c', 8)])\n",
        "\n",
        "print(join(a, b).collect())"
      ],
      "metadata": {
        "id": "AoS6gbOgOok-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80408759-e17d-468e-8e28-4886da412ece"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'b', 12), (1, 'b', 12), (1, 'a', 12), (1, 'a', 22)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksT9dLxgl9je"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>"
      ]
    }
  ]
}