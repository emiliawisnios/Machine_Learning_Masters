{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika GSN/DNN 2021/22 Lab5 - Batchnorm and Convnets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTwzhX8fBqs"
      },
      "source": [
        "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "This exercise covers two aspects:\n",
        "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch.\n",
        "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "\n",
        "Tasks:\n",
        "1. Check that the given implementation reaches 95% test accuracy for\n",
        "   architecture input-64-64-10 in a few thousand batches.\n",
        "2. Improve initialization and check that the network learns much faster\n",
        "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.\n",
        "3. Check, that with proper initialization we can train architecture\n",
        "   input-64-64-64-64-64-10, while with bad initialization it does\n",
        "   not even get off the ground.\n",
        "4. Add dropout implemented in pytorch\n",
        "5. Check that with 10 hidden layers (64 units each) even with proper\n",
        "    initialization the network has a hard time to start learning.\n",
        "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
        "    * compute batch mean and variance\n",
        "    * add new variables beta and gamma\n",
        "    * check that the networks learns much faster for 5 layers\n",
        "    * check that the network learns even for 10 hidden layers.\n",
        "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYAsziKffBFV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtap4QCfBH8"
      },
      "source": [
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = Parameter(torch.Tensor(out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        #self.weight.data.normal_(mean=0,std=0.25)\n",
        "        init.xavier_normal_(self.weight)\n",
        "        init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r = x.matmul(self.weight.t())\n",
        "        r += self.bias\n",
        "        return r"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9JctYsFFtmW"
      },
      "source": [
        "def batch_normalization(x, gamma, beta, moving_mean, moving_var, eps=1e-5, momentum=0.9):\n",
        "    if not torch.is_grad_enabled():\n",
        "        x_norm = (x - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        mean = x.mean(dim=0, keepdims=True)\n",
        "        var = ((x - mean) ** 2).mean(dim=0, keepdims=True)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + eps)\n",
        "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "    x = gamma * x_norm + beta\n",
        "    return x, moving_mean.data, moving_var.data\n",
        "\n",
        "\n",
        "class BatchNorm(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.beta = nn.Parameter(torch.zeros(1,64))\n",
        "    self.gamma = nn.Parameter(torch.ones(1,64))\n",
        "    self.moving_mean = torch.zeros(1,64)\n",
        "    self.moving_var = torch.ones(1,64)\n",
        " \n",
        "  def forward(self, X, eps=1e-5, momentum=0.9):\n",
        "    if self.moving_mean.device != X.device:\n",
        "      self.moving_mean = self.moving_mean.to(X.device)\n",
        "      self.moving_var = self.moving_var.to(X.device)\n",
        "    X, self.moving_mean, self.moving_var = batch_normalization(X, self.gamma, self.beta, \n",
        "                                                                   self.moving_mean, self.moving_var)\n",
        "    return X\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJxmGUUFWc4"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_hidden_layers=4, dropout_prob=0.1, use_dropout=False):\n",
        "        super(Net, self).__init__()\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.use_dropout = use_dropout\n",
        "\n",
        "\n",
        "        self.input_layer = Linear(784, 64)\n",
        "        self.hidden_layers = [Linear(64, 64) for _ in range(self.num_hidden_layers)]\n",
        "        self.output_layer = Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(self.dropout_prob)\n",
        "        self.batch_norm = [BatchNorm() for _ in range(self.num_hidden_layers)]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.input_layer(x))\n",
        "\n",
        "        for i in range(self.num_hidden_layers):\n",
        "            x = self.batch_norm[i](self.hidden_layers[i](x))\n",
        "            x = F.relu(x)\n",
        "            if self.use_dropout:\n",
        "              x = self.dropout(x)\n",
        "\n",
        "        return self.output_layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgfUP23AfBMd"
      },
      "source": [
        "class MnistTrainer(object):\n",
        "    def __init__(self, batch_size):\n",
        "        transform = transforms.Compose(\n",
        "                [transforms.ToTensor()])\n",
        "        self.trainset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            download=True,\n",
        "            train=True,\n",
        "            transform=transform)\n",
        "        self.trainloader = torch.utils.data.DataLoader(\n",
        "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        self.testset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            train=False,\n",
        "            download=True, transform=transform)\n",
        "        self.testloader = torch.utils.data.DataLoader(\n",
        "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    def train(self):\n",
        "        net = Net()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "        for epoch in range(20):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for data in self.testloader:\n",
        "                    images, labels = data\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
        "                total, 100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezvIQbgsfBRT",
        "outputId": "15d04d17-628b-4420-bb57-6abae3d9d1d4"
      },
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.699\n",
            "[1,   200] loss: 0.349\n",
            "[1,   300] loss: 0.304\n",
            "[1,   400] loss: 0.277\n",
            "Accuracy of the network on the 10000 test images: 93.21 %\n",
            "[2,   100] loss: 0.225\n",
            "[2,   200] loss: 0.213\n",
            "[2,   300] loss: 0.224\n",
            "[2,   400] loss: 0.210\n",
            "Accuracy of the network on the 10000 test images: 94.47 %\n",
            "[3,   100] loss: 0.185\n",
            "[3,   200] loss: 0.177\n",
            "[3,   300] loss: 0.194\n",
            "[3,   400] loss: 0.174\n",
            "Accuracy of the network on the 10000 test images: 95.01 %\n",
            "[4,   100] loss: 0.156\n",
            "[4,   200] loss: 0.160\n",
            "[4,   300] loss: 0.157\n",
            "[4,   400] loss: 0.173\n",
            "Accuracy of the network on the 10000 test images: 94.79 %\n",
            "[5,   100] loss: 0.154\n",
            "[5,   200] loss: 0.150\n",
            "[5,   300] loss: 0.133\n",
            "[5,   400] loss: 0.152\n",
            "Accuracy of the network on the 10000 test images: 95.39 %\n",
            "[6,   100] loss: 0.125\n",
            "[6,   200] loss: 0.128\n",
            "[6,   300] loss: 0.132\n",
            "[6,   400] loss: 0.143\n",
            "Accuracy of the network on the 10000 test images: 95.49 %\n",
            "[7,   100] loss: 0.118\n",
            "[7,   200] loss: 0.124\n",
            "[7,   300] loss: 0.125\n",
            "[7,   400] loss: 0.135\n",
            "Accuracy of the network on the 10000 test images: 95.49 %\n",
            "[8,   100] loss: 0.110\n",
            "[8,   200] loss: 0.119\n",
            "[8,   300] loss: 0.120\n",
            "[8,   400] loss: 0.116\n",
            "Accuracy of the network on the 10000 test images: 95.62 %\n",
            "[9,   100] loss: 0.108\n",
            "[9,   200] loss: 0.106\n",
            "[9,   300] loss: 0.111\n",
            "[9,   400] loss: 0.113\n",
            "Accuracy of the network on the 10000 test images: 95.48 %\n",
            "[10,   100] loss: 0.104\n",
            "[10,   200] loss: 0.103\n",
            "[10,   300] loss: 0.105\n",
            "[10,   400] loss: 0.110\n",
            "Accuracy of the network on the 10000 test images: 95.87 %\n",
            "[11,   100] loss: 0.093\n",
            "[11,   200] loss: 0.097\n",
            "[11,   300] loss: 0.102\n",
            "[11,   400] loss: 0.102\n",
            "Accuracy of the network on the 10000 test images: 95.75 %\n",
            "[12,   100] loss: 0.084\n",
            "[12,   200] loss: 0.091\n",
            "[12,   300] loss: 0.090\n",
            "[12,   400] loss: 0.099\n",
            "Accuracy of the network on the 10000 test images: 95.67 %\n",
            "[13,   100] loss: 0.080\n",
            "[13,   200] loss: 0.091\n",
            "[13,   300] loss: 0.088\n",
            "[13,   400] loss: 0.093\n",
            "Accuracy of the network on the 10000 test images: 95.73 %\n",
            "[14,   100] loss: 0.076\n",
            "[14,   200] loss: 0.086\n",
            "[14,   300] loss: 0.084\n",
            "[14,   400] loss: 0.093\n",
            "Accuracy of the network on the 10000 test images: 95.77 %\n",
            "[15,   100] loss: 0.077\n",
            "[15,   200] loss: 0.083\n",
            "[15,   300] loss: 0.079\n",
            "[15,   400] loss: 0.087\n",
            "Accuracy of the network on the 10000 test images: 95.78 %\n",
            "[16,   100] loss: 0.069\n",
            "[16,   200] loss: 0.078\n",
            "[16,   300] loss: 0.087\n",
            "[16,   400] loss: 0.091\n",
            "Accuracy of the network on the 10000 test images: 95.85 %\n",
            "[17,   100] loss: 0.073\n",
            "[17,   200] loss: 0.080\n",
            "[17,   300] loss: 0.077\n",
            "[17,   400] loss: 0.076\n",
            "Accuracy of the network on the 10000 test images: 96.12 %\n",
            "[18,   100] loss: 0.070\n",
            "[18,   200] loss: 0.072\n",
            "[18,   300] loss: 0.075\n",
            "[18,   400] loss: 0.081\n",
            "Accuracy of the network on the 10000 test images: 95.88 %\n",
            "[19,   100] loss: 0.070\n",
            "[19,   200] loss: 0.063\n",
            "[19,   300] loss: 0.069\n",
            "[19,   400] loss: 0.080\n",
            "Accuracy of the network on the 10000 test images: 95.7 %\n",
            "[20,   100] loss: 0.063\n",
            "[20,   200] loss: 0.070\n",
            "[20,   300] loss: 0.076\n",
            "[20,   400] loss: 0.064\n",
            "Accuracy of the network on the 10000 test images: 95.93 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFBx-iBkLyhc"
      },
      "source": [
        "def batch_norm2d(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "    if not torch.is_grad_enabled():\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        assert len(X.shape) == 4\n",
        "        mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "        var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "    Y = gamma * X_hat + beta\n",
        "    return Y, moving_mean.data, moving_var.data\n",
        "\n",
        "class BatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, num_dims=4):\n",
        "        super().__init__()\n",
        "        shape = (1, num_features, 1, 1)\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm2d(X, self.gamma, \n",
        "                                                            self.beta, self.moving_mean,\n",
        "                                                            self.moving_var, eps=1e-5, \n",
        "                                                            momentum=0.9)\n",
        "        return Y"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpK5JaXdR2FQ"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
        "        self.fc1 = nn.Linear(32 * 7 *7, 10)\n",
        "        self.batch_norm2d = BatchNorm2d(32)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.batch_norm2d(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyt6TJJfSW0A"
      },
      "source": [
        "class ConvMnistTrainer(object):\n",
        "    def __init__(self, batch_size):\n",
        "        transform = transforms.Compose(\n",
        "                [transforms.ToTensor()])\n",
        "        self.trainset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            download=True,\n",
        "            train=True,\n",
        "            transform=transform)\n",
        "        self.trainloader = torch.utils.data.DataLoader(\n",
        "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        self.testset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            train=False,\n",
        "            download=True, transform=transform)\n",
        "        self.testloader = torch.utils.data.DataLoader(\n",
        "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    def train(self):\n",
        "        net = ConvNet()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "        for epoch in range(20):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for data in self.testloader:\n",
        "                    images, labels = data\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
        "                total, 100 * correct / total))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "egX2T-Q9Seag",
        "outputId": "eec9e4a8-67c2-48f1-9cd7-1e5b9c2b407b"
      },
      "source": [
        "trainer = ConvMnistTrainer(batch_size=128)\n",
        "trainer.train()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.506\n",
            "[1,   200] loss: 0.302\n",
            "[1,   300] loss: 0.226\n",
            "[1,   400] loss: 0.193\n",
            "Accuracy of the network on the 10000 test images: 95.34 %\n",
            "[2,   100] loss: 0.145\n",
            "[2,   200] loss: 0.143\n",
            "[2,   300] loss: 0.132\n",
            "[2,   400] loss: 0.121\n",
            "Accuracy of the network on the 10000 test images: 96.6 %\n",
            "[3,   100] loss: 0.110\n",
            "[3,   200] loss: 0.106\n",
            "[3,   300] loss: 0.109\n",
            "[3,   400] loss: 0.102\n",
            "Accuracy of the network on the 10000 test images: 97.22 %\n",
            "[4,   100] loss: 0.092\n",
            "[4,   200] loss: 0.090\n",
            "[4,   300] loss: 0.103\n",
            "[4,   400] loss: 0.090\n",
            "Accuracy of the network on the 10000 test images: 97.47 %\n",
            "[5,   100] loss: 0.079\n",
            "[5,   200] loss: 0.090\n",
            "[5,   300] loss: 0.077\n",
            "[5,   400] loss: 0.087\n",
            "Accuracy of the network on the 10000 test images: 97.79 %\n",
            "[6,   100] loss: 0.073\n",
            "[6,   200] loss: 0.077\n",
            "[6,   300] loss: 0.074\n",
            "[6,   400] loss: 0.072\n",
            "Accuracy of the network on the 10000 test images: 98.02 %\n",
            "[7,   100] loss: 0.070\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-66faec273d56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMnistTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-4288342bdd49>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-734bed4fc7ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}